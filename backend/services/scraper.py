import requests
from bs4 import BeautifulSoup
from typing import Dict, Optional
import re
from urllib.parse import urljoin

class ImageScraper:
    """æŒ‡å®šã•ã‚ŒãŸURLã‹ã‚‰ç‰¹å®šã®CSSã‚»ãƒ¬ã‚¯ã‚¿ã§ç”»åƒã‚’æŠ½å‡ºã™ã‚‹ã‚¯ãƒ©ã‚¹"""

    def __init__(self, url: str):
        self.url = url
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })

    def extract_images(self) -> Dict[str, Optional[str]]:
        """
        ãƒšãƒ¼ã‚¸ã‹ã‚‰ç”»åƒURLã‚’æŠ½å‡º
        Returns:
            {
                'logo_url': str or None,
                'character_url': str or None
            }
        """
        try:
            response = self.session.get(self.url, timeout=10)
            response.raise_for_status()
            soup = BeautifulSoup(response.content, 'html.parser')

            logo_url = self._extract_logo(soup)
            character_url = self._extract_character(soup)

            return {
                'logo_url': logo_url,
                'character_url': character_url
            }
        except Exception as e:
            raise Exception(f"Failed to fetch page: {str(e)}")

    def _extract_logo(self, soup: BeautifulSoup) -> Optional[str]:
        """ãƒ˜ãƒƒãƒ€ãƒ¼ãƒ­ã‚´ç”»åƒã®URLã‚’æŠ½å‡º"""
        selector = '.wonder-header .wonder-header-inner .wonder-header-logo-wrapper .wonder-header-main .wonder-header-logo img'
        img_element = soup.select_one(selector)

        if img_element and img_element.get('src'):
            return urljoin(self.url, img_element['src'])
        return None

    def _extract_character(self, soup: BeautifulSoup) -> Optional[str]:
        """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ç”»åƒã®URLã‚’æŠ½å‡º"""
        # è¤‡æ•°ã®ã‚»ãƒ¬ã‚¯ã‚¿ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©¦ã™
        selectors = [
            '.wonder-cv .wonder-cv-wrapper .wonder-cv-back-person-img',  # å…ƒã®ã‚»ãƒ¬ã‚¯ã‚¿ãƒ¼
            '.wonder-cv-back-person-img',  # ã‚¯ãƒ©ã‚¹åã®ã¿
            'img.wonder-cv-back-person-img',  # imgã‚¿ã‚°ã«é™å®š
        ]

        element = None
        matched_selector = None
        for selector in selectors:
            print(f"ğŸ” ã‚»ãƒ¬ã‚¯ã‚¿ãƒ¼è©¦è¡Œ: {selector}")
            element = soup.select_one(selector)
            if element:
                matched_selector = selector
                print(f"âœ… ãƒãƒƒãƒã—ã¾ã—ãŸ: {selector}")
                print(f"   è¦ç´ ã‚¿ã‚°: {element.name}")
                print(f"   ã‚¯ãƒ©ã‚¹: {element.get('class', [])}")
                break
            else:
                print(f"âŒ ãƒãƒƒãƒã›ãš: {selector}")

        if not element:
            print("âŒ ã™ã¹ã¦ã®ã‚»ãƒ¬ã‚¯ã‚¿ãƒ¼ã§ãƒãƒƒãƒã›ãš")
            # ãƒ‡ãƒãƒƒã‚°: wonder-cv-back-person-img ã‚’å«ã‚€ã™ã¹ã¦ã®è¦ç´ ã‚’æ¤œç´¢
            all_matches = soup.find_all(class_=lambda x: x and 'wonder-cv-back-person-img' in x)
            print(f"ğŸ” 'wonder-cv-back-person-img' ã‚’å«ã‚€è¦ç´ æ•°: {len(all_matches)}")
            for idx, el in enumerate(all_matches[:3]):  # æœ€åˆã®3ã¤ã ã‘è¡¨ç¤º
                print(f"   [{idx}] ã‚¿ã‚°: {el.name}, ã‚¯ãƒ©ã‚¹: {el.get('class', [])}, src: {el.get('src', 'ãªã—')[:50]}")
            return None

        # è¦ç´ è‡ªä½“ãŒ img ã‚¿ã‚°ã®å ´åˆï¼ˆæœ€å„ªå…ˆï¼‰
        if element.name == 'img' and element.get('src'):
            src = element.get('src')
            print(f"âœ… imgã‚¿ã‚°ã®srcå±æ€§ã‹ã‚‰å–å¾—: {src[:100]}")
            return urljoin(self.url, src)

        # background-image ã‹ã‚‰ URL ã‚’æŠ½å‡º
        style = element.get('style', '')
        match = re.search(r'url\(["\']?([^"\']+)["\']?\)', style)
        if match:
            url = match.group(1)
            print(f"âœ… background-imageã‹ã‚‰å–å¾—: {url[:100]}")
            return urljoin(self.url, url)

        # ã¾ãŸã¯å­è¦ç´ ã® img ã‚¿ã‚°ã‚’æ¢ã™
        img_element = element.find('img')
        if img_element and img_element.get('src'):
            src = img_element.get('src')
            print(f"âœ… å­è¦ç´ ã®imgã‚¿ã‚°ã‹ã‚‰å–å¾—: {src[:100]}")
            return urljoin(self.url, src)

        print("âŒ ç”»åƒURLã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
        return None

    def download_image(self, image_url: str) -> bytes:
        """ç”»åƒURLã‹ã‚‰ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        try:
            response = self.session.get(image_url, timeout=10)
            response.raise_for_status()
            return response.content
        except Exception as e:
            raise Exception(f"Failed to download image from {image_url}: {str(e)}")
